{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc116504ac0419ed",
   "metadata": {},
   "source": [
    "The cell below is used to create a Golden Standard csv file, by reading the 'tagged_dataset.json.  Used to check if the model's NER prediction is correct.\n",
    "\n",
    "Format:\n",
    "| FILE_PATH                                               | LESSOR_NAME      | LESSEE_NAME      | PROPERTY_ADDRESS                                 | LEASE_START_DATE | LEASE_END_DATE   | RENT_AMOUNT | SECURITY_DEPOSIT_AMOUNT |\n",
    "|----------------------------------------------------------|------------------|------------------|--------------------------------------------------|------------------|------------------|-------------|--------------------------|\n",
    "| ./datasets/dataset-master/Lease_Agreement_1.docx   | Ashley Martinez  | Sarah Williams   | 5316 Pine Rd, Franklin, CA 70457                 | May 26, 2025     | May 26, 2026     | $1038       |  $1245                    |\n",
    "| ./datasets/dataset-master/Lease_Agreement_2.docx  | Ashley Jones     | Jessica Miller   | 538 Spruce Ct, Springfield, NY 82660             | December 16, 2024| December 16, 2025| $1746       |  $2095                    |\n",
    "| ./datasets/dataset-master/Lease_Agreement_3.docx   | Brian Miller     | Amanda Garcia    | 1807 Chestnut Blvd, Fairview, CA 68967           | September 20, 2024| September 20, 2025| $2611     |  $3133                    |\n",
    "| ./datasets/dataset-master/Lease_Agreement_4.docx   | David Hernandez  | Michael Johnson  | 2658 Elm St, Franklin, GA 71686                  | May 28, 2025     | May 28, 2026     | $3330       |  $3996                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b6a180206652f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T12:45:14.952966Z",
     "start_time": "2025-08-03T12:45:13.985448Z"
    }
   },
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame(columns=['FILE_PATH', 'LESSOR_NAME', 'LESSEE_NAME', 'PROPERTY_ADDRESS', 'LEASE_START_DATE', 'LEASE_END_DATE', 'RENT_AMOUNT', 'SECURITY_DEPOSIT_AMOUNT'])\n",
    "\n",
    "def data_preprocessing(data):\n",
    "    for f in data:\n",
    "        file_name = f[\"file_path\"]\n",
    "        doc_path = file_name\n",
    "        doc = Document(doc_path)\n",
    "        text = \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()]).strip()\n",
    "\n",
    "        # Tokenize by whitespace, and track char positions\n",
    "        tokens = []\n",
    "        token_spans = []\n",
    "        start = 0\n",
    "        for word in text.split():\n",
    "            start = text.find(word, start)  # Find next occurrence\n",
    "            end = start + len(word)\n",
    "            tokens.append(word)\n",
    "            token_spans.append((start, end))\n",
    "            start = end\n",
    "\n",
    "        # Initialize all labels to 0 (\"O\")\n",
    "        labels = [0] * len(tokens)\n",
    "        row =[file_name]\n",
    "        # Map character spans to token indices\n",
    "        for entity_name, span in f[\"entities\"].items():\n",
    "            ent_start = span[\"start\"]\n",
    "            ent_end = span[\"end\"]\n",
    "            row.append(text[ent_start:ent_end])\n",
    "        dataframe.loc[len(dataframe)] = row\n",
    "\n",
    "    # Save to CSV\n",
    "    dataframe.to_csv(\"golden_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02b84612008c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T12:45:16.208560Z",
     "start_time": "2025-08-03T12:45:15.847214Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./tagged_testing_dataset.json\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)\n",
    "    data_preprocessing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d68618f1e0365",
   "metadata": {},
   "source": [
    "compare_result(pred_file, golden_file, result_file)\n",
    "\n",
    "pred_file: Prediction result csv file path\n",
    "\n",
    "golden_file: Original golden standard csv file path\n",
    "\n",
    "result_file: File path to save the result file. By default, it is './result.csv'\n",
    "\n",
    "What it does:\n",
    "\n",
    "1. Loads both CSVs into DataFrames.\n",
    "\n",
    "2. Iterates through each row in the pred_file.\n",
    "\n",
    "3. Finds the corresponding row in the golden_file by matching FILE_PATH.\n",
    "\n",
    "4. Compares each field in the row.\n",
    "\n",
    "5. Appends a new row to the result:\n",
    "\n",
    "    1 if prediction matches the golden truth.\n",
    "\n",
    "    0 if it doesn't.\n",
    "\n",
    "6. Saves the result as a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcff02c2c3851bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:41:14.347433Z",
     "start_time": "2025-08-03T14:41:14.337931Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def exact_match_results(pred_file, golden_file, result_file = 'result.csv'):\n",
    "    # Load prediction and original CSVs\n",
    "    pred_df = pd.read_csv(pred_file)\n",
    "    orig_df = pd.read_csv(golden_file)\n",
    "\n",
    "    # Output comparison dataframe\n",
    "    result_dataframe = pd.DataFrame(columns=[\n",
    "        'FILE_PATH', 'LESSOR_NAME', 'LESSEE_NAME',\n",
    "        'PROPERTY_ADDRESS', 'LEASE_START_DATE', 'LEASE_END_DATE',\n",
    "        'RENT_AMOUNT', 'SECURITY_DEPOSIT_AMOUNT'\n",
    "    ])\n",
    "\n",
    "    # Iterate through prediction file\n",
    "    for i in range(len(pred_df)):\n",
    "        file_path = pred_df.iloc[i]['FILE_PATH']\n",
    "        orig = orig_df[orig_df['FILE_PATH'] == file_path]\n",
    "\n",
    "        # Skip if no match in original\n",
    "        if orig.empty:\n",
    "            continue\n",
    "\n",
    "        pred_row = pred_df[pred_df['FILE_PATH'] == file_path].iloc[0]\n",
    "        orig_row = orig.iloc[0]\n",
    "        print(pred_row['LESSOR_NAME'], orig_row['LESSEE_NAME'])\n",
    "        comparison = {\n",
    "            'FILE_PATH': file_path,\n",
    "            'LESSOR_NAME': int(pred_row['LESSOR_NAME'] == orig_row['LESSOR_NAME']),\n",
    "            'LESSEE_NAME': int(pred_row['LESSEE_NAME'] == orig_row['LESSEE_NAME']),\n",
    "            'PROPERTY_ADDRESS': int(pred_row['PROPERTY_ADDRESS'] == orig_row['PROPERTY_ADDRESS']),\n",
    "            'LEASE_START_DATE': int(pred_row['LEASE_START_DATE'] == orig_row['LEASE_START_DATE']),\n",
    "            'LEASE_END_DATE': int(pred_row['LEASE_END_DATE'] == orig_row['LEASE_END_DATE']),\n",
    "            #'RENT_AMOUNT': int(pred_row['RENT_AMOUNT'] == orig_row['RENT_AMOUNT']),\n",
    "            'SECURITY_DEPOSIT_AMOUNT': int(pred_row['SECURITY_DEPOSIT_AMOUNT'] == orig_row['SECURITY_DEPOSIT_AMOUNT']),\n",
    "        }\n",
    "\n",
    "        result_dataframe = pd.concat([result_dataframe, pd.DataFrame([comparison])], ignore_index=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    result_dataframe.to_csv(result_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525bfd63bb9496c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:41:38.503352Z",
     "start_time": "2025-08-03T14:41:38.489832Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def partial_match_results(pred_file, golden_file, result_file='partial_result.csv'):\n",
    "    pred_df = pd.read_csv(pred_file)\n",
    "    orig_df = pd.read_csv(golden_file)\n",
    "\n",
    "    columns = [\n",
    "        'LESSOR_NAME', 'LESSEE_NAME', 'PROPERTY_ADDRESS',\n",
    "        'LEASE_START_DATE', 'LEASE_END_DATE',\n",
    "         'SECURITY_DEPOSIT_AMOUNT'\n",
    "    ]#'RENT_AMOUNT',\n",
    "\n",
    "    result_dataframe = pd.DataFrame(columns=['FILE_PATH'] + columns)\n",
    "\n",
    "    def fuzzy_score(pred, gold):\n",
    "        if pd.isna(pred) or pd.isna(gold):\n",
    "            return 0.0\n",
    "        pred = str(pred).strip()\n",
    "        gold = str(gold).strip()\n",
    "        score = fuzz.token_sort_ratio(pred, gold)\n",
    "        if score >= 95:\n",
    "            return 1.0\n",
    "        elif score >= 85:\n",
    "            return 0.75\n",
    "        elif score >= 70:\n",
    "            return 0.5\n",
    "        elif score >= 50:\n",
    "            return 0.25\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    for i in range(len(pred_df)):\n",
    "        file_path = pred_df.iloc[i]['FILE_PATH']\n",
    "        orig = orig_df[orig_df['FILE_PATH'] == file_path]\n",
    "\n",
    "        if orig.empty:\n",
    "            continue\n",
    "\n",
    "        pred_row = pred_df[pred_df['FILE_PATH'] == file_path].iloc[0]\n",
    "        orig_row = orig.iloc[0]\n",
    "\n",
    "        comparison = {'FILE_PATH': file_path}\n",
    "        for col in columns:\n",
    "            comparison[col] = fuzzy_score(pred_row[col], orig_row[col])\n",
    "\n",
    "        result_dataframe = pd.concat([result_dataframe, pd.DataFrame([comparison])], ignore_index=True)\n",
    "\n",
    "    result_dataframe.to_csv(result_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e940662497f432d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:41:39.502748Z",
     "start_time": "2025-08-03T14:41:39.391140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEPC MILTON PARK NO. ADAPTIMMUNE THERAPEUTICS PLC\n",
      "YOUHAN YOUXINPAI (BEIJING)\n",
      "UCARSHOW HK LIMITED UCARBUY HOLDING LIMITED\n",
      "UXIN LIMITED GLORYFIN INTERNATIONAL GROUP HOLDING COMPANY LIMITED\n",
      "MEPC MILTON PARK NO. OXFORD IMMUNOTEC LIMITED\n",
      "George Feldenkreis Supreme International, Inc\n",
      "nan MICROSOFT CHINA CO., LTD\n",
      "nan JINKO SOLAR CO., LTD\n",
      "nan CHINA TIAN YUAN SPECIALTY CROP TECHNOLOGIES CO., LTD\n",
      "BOYU FINANCING LEASE KAIFENG FINANCING LEASE\n",
      "SICHUAN YOUXINPAI YOUXINPAI (BEIJING)\n",
      "nan YOUXIN HONG KONG LIMITED\n",
      "YOUXIN LIMITED PERFECT HARMONY GROUP LIMITED\n",
      "HENZHEN NEW TAOYUAN INDUSTRIAL CO., LTD. SHENZHEN GUANGRONG ELECTRONIC CO., LTD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/py5q5l5s6cq6v2rjnlwlwkw00000gn/T/ipykernel_27395/50599956.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_dataframe = pd.concat([result_dataframe, pd.DataFrame([comparison])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "exact_match_results('fine_tuned_spacy_testing_results.csv', 'golden_data.csv', 'fine_tuned_spacy_exact_result.csv')\n",
    "partial_match_results('fine_tuned_spacy_testing_results.csv', 'golden_data.csv', 'fine_tuned_spacy_partial_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af8fe6f1cc9a03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:39:04.467746Z",
     "start_time": "2025-08-03T14:39:04.457905Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_result_csv(result_file, threshold=0.5):\n",
    "    df = pd.read_csv(result_file)\n",
    "\n",
    "    if 'FILE_PATH' in df.columns:\n",
    "        df = df.drop(columns=['FILE_PATH'])\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        values = df[col].fillna(0).astype(float)\n",
    "\n",
    "        tp = (values >= threshold).sum()\n",
    "        total_pred = len(values)\n",
    "        total_gold = len(values)  # assumes gold data is one row per file\n",
    "\n",
    "        precision = tp / total_pred if total_pred else 0\n",
    "        recall = tp / total_gold if total_gold else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "        metrics[col] = {\n",
    "            'total': total_pred,\n",
    "            'true_positives': int(tp),\n",
    "            'precision': round(precision, 3),\n",
    "            'recall': round(recall, 3),\n",
    "            'f1_score': round(f1, 3)\n",
    "        }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8878649855edf7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:42:16.449538Z",
     "start_time": "2025-08-03T14:42:16.428962Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"fine_tuned_spacy_partial_result\"\n",
    "evaluation_results = evaluate_result_csv(f\"{file_name}.csv\")\n",
    "\n",
    "# save evaluation results to a json file\n",
    "with open(\"fine_tuned_spacy_evaluation_results.json\", \"w\") as f:\n",
    "    json.dump(evaluation_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12922b8849d3540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
